{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Urban Sound Classification using Convolutional Neural Networks with Keras: Theory and Implementation\n",
    "\n",
    "https://medium.com/gradientcrescent/urban-sound-classification-using-convolutional-neural-networks-with-keras-theory-and-486e92785df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UrbanSound dataset consists of 8732 labelled short (less than 4 s) sound excerpts of urban sounds from 10 different classes. Both our training and test datasets consist of .wav files and an accompanying .csv spreadsheet detailing their ID and in the case of the training data, their correct descriptions, which serve as their labels. In order to convert our data into spectrogram representations, we will utilize LibROSA, an open-source python package for music and audio analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UrbanSoundDataset\n",
    ": https://urbansounddataset.weebly.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 다른 Kaggle site에 올려진 데이터. weebly꺼 말고 이걸 받아서 사용함.\n",
    "```\n",
    "train.zip (3GB) \n",
    "test.zip (2GB)\n",
    "```\n",
    "The dataset is called UrbanSound and contains 8732 labeled sound excerpts (<=4s) of urban sounds from 10 classes: - The dataset contains 8732 sound excerpts (<=4s) of urban sounds from 10 classes, namely: Air Conditioner Car Horn Children Playing Dog bark Drilling Engine Idling Gun Shot Jackhammer Siren Street Music The attributes of data are as follows: ID – Unique ID of sound excerpt Class – type of sound\n",
    "\n",
    "https://www.kaggle.com/devilsknight/sound-classification-using-spectrogram-images\n",
    "\n",
    "Source of the dataset : https://drive.google.com/drive/folders/0By0bAi7hOBAFUHVXd1JCN3MwTEU\n",
    "\n",
    "Source of research document : https://serv.cusp.nyu.edu/projects/urbansounddataset/salamon_urbansound_acmmm14.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"{}\".format(3) # gpu idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  train\r\n"
     ]
    }
   ],
   "source": [
    "dataloc='/home/seung/dataset/UrbanSound_devilsknight'\n",
    "!ls $dataloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import memory_usage\n",
    "#https://github.com/giampaolo/psutil/issues/1143#issuecomment-334695523\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "#import tqdm as tqdm\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!apt-get install libav-tools -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to convert our data into spectrogram representations, we will utilize LibROSA, an open-source python package for music and audio analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "import gc\n",
    "from path import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DDUtil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /home/seung/data/out-audio1//n21_CL1\n"
     ]
    }
   ],
   "source": [
    "n_classes = 1\n",
    "bCreateFile=False#False\n",
    "base_dir_out = '/home/seung/data/out-audio1/'\n",
    "outDir = '{}/n21_CL{}'.format(base_dir_out, n_classes)\n",
    "MakeDir(outDir)\n",
    "MakeDir(base_dir_out+'_train')\n",
    "MakeDir(base_dir_out+'_test')\n",
    "\n",
    "print('Created {}'.format(outDir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n21_CL1  n21_CL1model.h5  _test  _train\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/seung/data/out-audio1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~/.venv/py3Keras/bin/pip install -I path.py==7.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(outdir, filename,name):\n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load(filename, sr=None)\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    fout  = outdir + '/_train/' + name + '.jpg'\n",
    "    plt.savefig(fout, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del fout,name,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram_test(outdir, filename, name):\n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load(filename, sr=None)\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    #fout  = Path(outdir +'/test/' + name + '.jpg')\n",
    "    fout  = outdir +'/_test/' + name + '.jpg'\n",
    "    fig.savefig(fout, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del fout,name,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : (5435,)\n",
      "Test : (3297,)\n"
     ]
    }
   ],
   "source": [
    "Data_dir=np.array(glob(dataloc+'/train/Train/*'))\n",
    "Test_dir=np.array(glob(dataloc+'/test/Test/*'))\n",
    "print('Train : {}'.format(Data_dir.shape))\n",
    "print('Test : {}'.format(Test_dir.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/home/seung/dataset/UrbanSound_devilsknight/train/Train/7893.wav',\n",
       "       '/home/seung/dataset/UrbanSound_devilsknight/train/Train/5178.wav',\n",
       "       '/home/seung/dataset/UrbanSound_devilsknight/train/Train/495.wav'],\n",
       "      dtype='<U64')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_dir[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 373.92 MiB, increment: 0.03 MiB\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "%memit\n",
    "i=0\n",
    "if bCreateFile:\n",
    "    with tqdm(total=len(Data_dir[i:i+2000])) as pbar:\n",
    "        for file in Data_dir[i:i+2000]:\n",
    "            filename,name = file,file.split('/')[-1].split('.')[0]\n",
    "            create_spectrogram(base_dir_out,filename,name)\n",
    "            pbar.update(1)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Data_dir[i:i+2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 373.93 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit \n",
    "i=2000\n",
    "if bCreateFile:\n",
    "    with tqdm(total=len(Data_dir[i:i+2000])) as pbar:\n",
    "        for file in Data_dir[i:i+2000]:\n",
    "            filename,name = file,file.split('/')[-1].split('.')[0]\n",
    "            create_spectrogram(base_dir_out,filename,name)\n",
    "            pbar.update(1)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 373.93 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit \n",
    "i=4000\n",
    "if bCreateFile:\n",
    "    with tqdm(total=len(Data_dir[i:])) as pbar:\n",
    "        for file in Data_dir[i:]:\n",
    "            filename,name = file,file.split('/')[-1].split('.')[0]\n",
    "            create_spectrogram(base_dir_out,filename,name)\n",
    "            pbar.update(1)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the same for our test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 373.94 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit\n",
    "i=0\n",
    "if bCreateFile:\n",
    "    with tqdm(total=len(Test_dir[i:i+2000])) as pbar:\n",
    "        for file in Test_dir[i:i+2000]:\n",
    "            filename,name = file,file.split('/')[-1].split('.')[0]\n",
    "            create_spectrogram_test(base_dir_out,filename,name)\n",
    "            pbar.update(1)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 373.94 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit\n",
    "i=2000\n",
    "if bCreateFile:\n",
    "    with tqdm(total=len(Test_dir[i:])) as pbar:\n",
    "        for file in Test_dir[i:]:\n",
    "            filename,name = file,file.split('/')[-1].split('.')[0]\n",
    "            create_spectrogram_test(base_dir_out,filename,name)\n",
    "            pbar.update(1)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def append_ext(fn):\n",
    "    return fn+\".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  test.csv\r\n"
     ]
    }
   ],
   "source": [
    "dataloc_test=dataloc+'/test'\n",
    "dataloc_train=dataloc+'/train'\n",
    "\n",
    "!ls $dataloc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/seung/dataset/UrbanSound_devilsknight/train/train.csv\n",
      "/home/seung/dataset/UrbanSound_devilsknight/test/test.csv\n"
     ]
    }
   ],
   "source": [
    "csv_train = dataloc_train+'/train.csv'\n",
    "csv_test = dataloc_test+'/test.csv'\n",
    "print(csv_train)\n",
    "print(csv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf=pd.read_csv(csv_train,dtype=str)\n",
    "testdf=pd.read_csv(csv_test,dtype=str)\n",
    "traindf[\"ID\"]=traindf[\"ID\"].apply(append_ext)\n",
    "testdf[\"ID\"]=testdf[\"ID\"].apply(append_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             ID            Class\n",
       "0        0.jpg            siren\n",
       "1        1.jpg     street_music\n",
       "2        2.jpg         drilling\n",
       "3        3.jpg            siren\n",
       "4        4.jpg         dog_bark\n",
       "...        ...              ...\n",
       "5430  8725.jpg    engine_idling\n",
       "5431  8726.jpg         dog_bark\n",
       "5432  8727.jpg    engine_idling\n",
       "5433  8728.jpg    engine_idling\n",
       "5434  8729.jpg  air_conditioner\n",
       "\n",
       "[5435 rows x 2 columns]>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0.jpg\n",
       "1          1.jpg\n",
       "2          2.jpg\n",
       "3          3.jpg\n",
       "4          4.jpg\n",
       "          ...   \n",
       "5430    8725.jpg\n",
       "5431    8726.jpg\n",
       "5432    8727.jpg\n",
       "5433    8728.jpg\n",
       "5434    8729.jpg\n",
       "Name: ID, Length: 5435, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.5\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datagen = ImageDataGenerator(rescale=1./255.,validation_split=0.25)\n",
    "#datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n",
    "#datagen = ImageDataGenerator(rescale=1./255)\n",
    "#datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)\n",
    "#datagen=ImageDataGenerator(rescale=1./255.) # keras 2.1.2\n",
    "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4077 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=traindf,\n",
    "    directory=base_dir_out+'_train',\n",
    "    x_col=\"ID\",\n",
    "    y_col=\"Class\",\n",
    "    subset=\"training\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1358 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=traindf,\n",
    "    directory=base_dir_out+'_train',#directory=\"/kaggle/working/train/\",\n",
    "    x_col=\"ID\",\n",
    "    y_col=\"Class\",\n",
    "    subset=\"validation\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/seung/.venv/py368LatestKeras/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/seung/.venv/py368LatestKeras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 62, 62, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 31, 31, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 29, 29, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,679,626\n",
      "Trainable params: 2,679,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',  input_shape=(64,64,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizers.rmsprop(lr=0.0005, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP_SIZE_TRAIN=127\n",
      "STEP_SIZE_VALID=42\n"
     ]
    }
   ],
   "source": [
    "#Fitting keras model, no test gen for now\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "print('STEP_SIZE_TRAIN={}'.format(STEP_SIZE_TRAIN))\n",
    "print('STEP_SIZE_VALID={}'.format(STEP_SIZE_VALID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/seung/.venv/py368LatestKeras/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/300\n",
      "127/127 [==============================] - 8s 61ms/step - loss: 2.0879 - acc: 0.2250 - val_loss: 1.9103 - val_acc: 0.2798\n",
      "Epoch 2/300\n",
      "127/127 [==============================] - 6s 46ms/step - loss: 1.8128 - acc: 0.3397 - val_loss: 1.5106 - val_acc: 0.4902\n",
      "Epoch 3/300\n",
      "127/127 [==============================] - 6s 47ms/step - loss: 1.4266 - acc: 0.5131 - val_loss: 1.2013 - val_acc: 0.5905\n",
      "Epoch 4/300\n",
      "127/127 [==============================] - 6s 46ms/step - loss: 1.1874 - acc: 0.5911 - val_loss: 1.1088 - val_acc: 0.6471\n",
      "Epoch 5/300\n",
      "127/127 [==============================] - 6s 46ms/step - loss: 1.0178 - acc: 0.6616 - val_loss: 1.0502 - val_acc: 0.6523\n",
      "Epoch 6/300\n",
      "127/127 [==============================] - 6s 45ms/step - loss: 0.8861 - acc: 0.7083 - val_loss: 0.8487 - val_acc: 0.7413\n",
      "Epoch 7/300\n",
      "127/127 [==============================] - 6s 46ms/step - loss: 0.7832 - acc: 0.7408 - val_loss: 0.7744 - val_acc: 0.7579\n",
      "Epoch 8/300\n",
      "127/127 [==============================] - 6s 46ms/step - loss: 0.6782 - acc: 0.7746 - val_loss: 0.7082 - val_acc: 0.7632\n",
      "Epoch 9/300\n",
      "127/127 [==============================] - 6s 45ms/step - loss: 0.5947 - acc: 0.8042 - val_loss: 0.5673 - val_acc: 0.8205\n",
      "Epoch 10/300\n",
      "127/127 [==============================] - 6s 45ms/step - loss: 0.5192 - acc: 0.8356 - val_loss: 0.5558 - val_acc: 0.8258\n",
      "Epoch 11/300\n",
      "127/127 [==============================] - 6s 44ms/step - loss: 0.4775 - acc: 0.8403 - val_loss: 0.5436 - val_acc: 0.8371\n",
      "Epoch 12/300\n",
      "127/127 [==============================] - 6s 44ms/step - loss: 0.4055 - acc: 0.8652 - val_loss: 0.4405 - val_acc: 0.8725\n",
      "Epoch 13/300\n",
      " 17/127 [===>..........................] - ETA: 2s - loss: 0.3675 - acc: 0.8860"
     ]
    }
   ],
   "source": [
    "#STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "hist = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(generator=valid_generator, steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper center')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnmodel=outDir+'model.h5'\n",
    "print(fnmodel)\n",
    "model.save(fnmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
